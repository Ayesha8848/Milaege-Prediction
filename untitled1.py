# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16aNgTSFbudonNrGW93ufq4Zknt5b2lLL

# **MILEAGE** **PREDICTION** - **REGRESSION ANALYSIS**

**Source:**
This Dataset was taken from the StatLib library which is maintained at Carneige Mellon University. The dataset was used in 1983 American Statistical Association Exposition.

**Dataset Information:**
This dataset is a slightly modified version of the dataset provided in the StatLib library. This dataset concerns city-cycle fuel consumption in Miles per Gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes.

**Attribute Information:**
mpg: continuous
cylinders: multi-valued, discrete
displacement: continuous
horsepower: continuous
weight: continuous
acceleration: continuous
model year: multi-valued, discrete
origin: multi-valued, discrete
car name: string

### **Import Library**
"""

import pandas as pd

from sklearn import preprocessing

import seaborn as sns

import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression

from sklearn.neighbors import KNeighborsRegressor

from sklearn.tree import DecisionTreeRegressor

from sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error,r2_score

"""## **Import Data**"""

#READING DATA
data=pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/MPG.csv')

data.head()

data.nunique()

"""## **Data Preprocessing**"""

data.info()

data.describe()

"""## **Replacing Missing Values with Mean**"""

# MISSING VALUES
null_cols=[]
for i in data.columns:
    if data[i].isnull().sum().any():
           null_cols.append(i)
print(null_cols)
print(data.isna().sum())
data["horsepower"].fillna(data["horsepower"].mean(),inplace=True)

data.describe()

"""## **Converting Categorical attributes to numerical**"""

#CATEGORICAL TO NUMERICAL
le=preprocessing.LabelEncoder()
cat_cols=["origin","name"]
for i in cat_cols:
    encoded_labels=le.fit_transform(data[i])
    data.drop(i,axis="columns",inplace=True)
    data[i]=pd.DataFrame(encoded_labels)
print(data)

"""## **Data Visualization**"""

#PEARSON CORRELATION
correlation=data.corr(method='pearson')
print(correlation)
sns.heatmap(correlation,annot=True)
plt.show()

"""## **Defining Target Variable y and Feature x**"""

x=data.drop("mpg",axis="columns")
y=data["mpg"]

"""## **Data Standardization**"""

#STANDARDIZATION
sc=StandardScaler()
x=sc.fit_transform(x)
x=pd.DataFrame(x)
x.columns=['cylinders' ,'displacement', 'horsepower', 'weight', 'acceleration',
 'model_year', 'origin', 'name']

"""## **Train-Test split**"""

# TRAIN-TEST SPLIT
x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state=2529)

"""## **Linear Regression Model**"""

model=LinearRegression()
model.fit(x_train,y_train)
p=model.predict(x_test)
print(p)

"""**Model Accuracy**"""

print(mean_absolute_error(y_test,p))

print(mean_absolute_percentage_error(y_test,p))

print(model.score(x_test,y_test))

r2_score(y_test,p)

"""## **KNeighbors Regressor Model**"""

model=KNeighborsRegressor()
model.fit(x_train,y_train)
p=model.predict(x_test)
print(p)

"""**Model Accuracy**"""

print(mean_absolute_error(y_test,p))

print(mean_absolute_percentage_error(y_test,p))

print(model.score(x_test,y_test))

r2_score(y_test,p)

"""## **Decision Tree Regressor Model**"""

model=DecisionTreeRegressor()
model.fit(x_train,y_train)
p=model.predict(x_test)
print(p)

"""Model Accuracy"""

print(mean_absolute_error(y_test,p))

print(mean_absolute_percentage_error(y_test,p))

print(model.score(x_test,y_test))

r2_score(y_test,p)